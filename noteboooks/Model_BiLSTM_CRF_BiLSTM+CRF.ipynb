{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CHUNK 1: PREPROCESSING\n",
        "# ============================================\n",
        "!pip install sklearn-crfsuite spacy\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load Data\n",
        "filename = '/content/dataset.json'\n",
        "try:\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    data = []\n",
        "    print(\"Error: File dataset.json tidak ditemukan.\")\n",
        "\n",
        "# 2. Format Konverter\n",
        "def convert_to_word_level(item):\n",
        "    if 'data' in item and 'text' in item['data']:\n",
        "        text = item['data']['text']\n",
        "    elif 'text' in item:\n",
        "        text = item['text']\n",
        "    else:\n",
        "        return [], []\n",
        "\n",
        "    annotations = item.get('annotations', [])\n",
        "    if not annotations: return [], []\n",
        "\n",
        "    res = annotations[0].get('result', [])\n",
        "    tokens = text.split()\n",
        "    labels = ['O'] * len(tokens)\n",
        "\n",
        "    token_spans = []\n",
        "    current_pos = 0\n",
        "    for token in tokens:\n",
        "        start = text.find(token, current_pos)\n",
        "        end = start + len(token)\n",
        "        token_spans.append((start, end))\n",
        "        current_pos = end\n",
        "\n",
        "    for ann in res:\n",
        "        if 'value' in ann and 'labels' in ann['value']:\n",
        "            ann_start = ann['value']['start']\n",
        "            ann_end = ann['value']['end']\n",
        "            label_text = ann['value']['labels'][0]\n",
        "            for idx, (tok_start, tok_end) in enumerate(token_spans):\n",
        "                if max(tok_start, ann_start) < min(tok_end, ann_end):\n",
        "                    if tok_start == ann_start: labels[idx] = f\"B-{label_text}\"\n",
        "                    else: labels[idx] = f\"I-{label_text}\"\n",
        "    return tokens, labels\n",
        "\n",
        "all_tokens = []\n",
        "all_labels = []\n",
        "if data:\n",
        "    for item in data:\n",
        "        t, l = convert_to_word_level(item)\n",
        "        if t:\n",
        "            all_tokens.append(t)\n",
        "            all_labels.append(l)\n",
        "\n",
        "# 3. Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_tokens, all_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "def inject_noise(tokens_list, noise_ratio=0.25):\n",
        "    noisy_data = []\n",
        "    for tokens in tokens_list:\n",
        "        new_tokens = []\n",
        "        for token in tokens:\n",
        "            if random.random() < noise_ratio:\n",
        "                new_tokens.append(\"<UNK>\")\n",
        "            else:\n",
        "                new_tokens.append(token)\n",
        "        noisy_data.append(new_tokens)\n",
        "    return noisy_data\n",
        "\n",
        "X_test_noisy = inject_noise(X_test, noise_ratio=0.25)\n",
        "\n",
        "print(f\"Total Train: {len(X_train)}\")\n",
        "print(f\"Total Test : {len(X_test_noisy)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AC68E0uG913D",
        "outputId": "2b723904-b590-4004-c06f-af13702a446d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.7 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite) (0.9.11)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.12/dist-packages (from sklearn-crfsuite) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.6.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Total Train: 200\n",
            "Total Test : 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BiLSTM**"
      ],
      "metadata": {
        "id": "pxDDWg21BZlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CHUNK 2: BiLSTM\n",
        "# ============================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "tag2idx = {\"<PAD>\": 0}\n",
        "for sent in X_train:\n",
        "    for word in sent:\n",
        "        if word not in word2idx: word2idx[word] = len(word2idx)\n",
        "for tags in y_train:\n",
        "    for tag in tags:\n",
        "        if tag not in tag2idx: tag2idx[tag] = len(tag2idx)\n",
        "idx2tag = {v: k for k, v in tag2idx.items()}\n",
        "\n",
        "def encode_sequence(seq, mapping, unk_token=None):\n",
        "    return [mapping.get(w, mapping.get(unk_token, 0)) for w in seq]\n",
        "def pad_sequence(seq, max_len, pad_value=0):\n",
        "    if len(seq) > max_len: return seq[:max_len]\n",
        "    return seq + [pad_value] * (max_len - len(seq))\n",
        "\n",
        "MAX_LEN = 128\n",
        "X_train_enc = [pad_sequence(encode_sequence(s, word2idx, \"<UNK>\"), MAX_LEN) for s in X_train]\n",
        "y_train_enc = [pad_sequence(encode_sequence(t, tag2idx), MAX_LEN) for t in y_train]\n",
        "X_test_enc = [pad_sequence(encode_sequence(s, word2idx, \"<UNK>\"), MAX_LEN) for s in X_test_noisy]\n",
        "y_test_enc = [pad_sequence(encode_sequence(t, tag2idx), MAX_LEN) for t in y_test]\n",
        "\n",
        "train_loader = DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train_enc), torch.tensor(y_train_enc)), batch_size=16, shuffle=True)\n",
        "\n",
        "class BiLSTM_NER(nn.Module):\n",
        "    def __init__(self, vocab_size, tag_size):\n",
        "        super(BiLSTM_NER, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, 100, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(100, 32, batch_first=True, bidirectional=True, dropout=0.5, num_layers=2)\n",
        "        self.fc = nn.Linear(32 * 2, tag_size) # Sesuaikan input linear (32*2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(emb)\n",
        "        tag_space = self.fc(lstm_out)\n",
        "        return tag_space\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_bilstm = BiLSTM_NER(len(word2idx), len(tag2idx)).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model_bilstm.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(8):\n",
        "    model_bilstm.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model_bilstm(inputs).view(-1, len(tag2idx)), labels.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model_bilstm.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    inputs = torch.tensor(X_test_enc).to(device)\n",
        "    outputs = model_bilstm(inputs)\n",
        "    preds = torch.argmax(outputs, dim=2).cpu().numpy()\n",
        "    for i in range(len(preds)):\n",
        "        length = len(X_test[i])\n",
        "        y_pred.extend([idx2tag[p] for p in preds[i][:length]])\n",
        "        y_true.extend([idx2tag[t] for t in y_test_enc[i][:length]])\n",
        "\n",
        "labels_no_o = [l for l in tag2idx.keys() if l not in ['<PAD>', 'O']]\n",
        "print(\"\\n--- BiLSTM Report ---\")\n",
        "print(classification_report(y_true, y_pred, labels=labels_no_o, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kl5oxrh91z5",
        "outputId": "b6e94f21-604a-4ea7-f6a4-c6f13c5d74ae"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BiLSTM Report ---\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "         B-NOMOR_PUTUSAN       0.85      0.69      0.76        49\n",
            "         I-NOMOR_PUTUSAN       0.96      0.55      0.70        49\n",
            "         B-NAMA_TERDAKWA       0.76      0.56      0.64        70\n",
            "         I-NAMA_TERDAKWA       0.95      0.81      0.87       223\n",
            "I-TANGGAL_LAHIR_TERDAKWA       0.96      0.77      0.85       192\n",
            "        B-AGAMA_TERDAKWA       0.85      0.77      0.81        60\n",
            "     B-LOKASI_PENGADILAN       1.00      0.71      0.83        35\n",
            "     I-LOKASI_PENGADILAN       1.00      0.71      0.83        73\n",
            "         B-VONIS_PENJARA       1.00      0.33      0.50         6\n",
            "         I-VONIS_PENJARA       1.00      0.63      0.77        27\n",
            "                B-KORBAN       0.00      0.00      0.00         1\n",
            "                I-KORBAN       0.00      0.00      0.00         1\n",
            "   B-MODUS_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "   I-MODUS_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "         B-PASAL_DAKWAAN       0.00      0.00      0.00         0\n",
            "         I-PASAL_DAKWAAN       0.00      0.00      0.00         0\n",
            "        B-STATUS_PUTUSAN       0.00      0.00      0.00         0\n",
            "        I-STATUS_PUTUSAN       0.00      0.00      0.00         0\n",
            "       B-TANGGAL_PUTUSAN       0.00      0.00      0.00         0\n",
            "       I-TANGGAL_PUTUSAN       0.00      0.00      0.00         0\n",
            "            B-NAMA_HAKIM       0.00      0.00      0.00         0\n",
            "            I-NAMA_HAKIM       0.00      0.00      0.00         0\n",
            "  B-AKIBAT_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "  I-AKIBAT_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "        I-AGAMA_TERDAKWA       0.00      0.00      0.00         1\n",
            "B-TANGGAL_LAHIR_TERDAKWA       0.00      0.00      0.00         3\n",
            "\n",
            "               micro avg       0.93      0.72      0.81       790\n",
            "               macro avg       0.36      0.25      0.29       790\n",
            "            weighted avg       0.93      0.72      0.81       790\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- HITUNG ACCURACY MANUAL ---\n",
        "print(\"\\n--- BiLSTM Accuracy Metrics ---\")\n",
        "real_idx = [i for i, label in enumerate(y_true) if label != 'O']\n",
        "acc_entity = accuracy_score([y_true[i] for i in real_idx], [y_pred[i] for i in real_idx])\n",
        "print(f\"Accuracy BiLSTM: {acc_entity:.4f} ({acc_entity*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6yuQqB_EQQz",
        "outputId": "d0c5b723-31f7-4c54-e375-ec91be89378e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BiLSTM Accuracy Metrics ---\n",
            "Accuracy BiLSTM: 0.7203 (72.03%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CRF**"
      ],
      "metadata": {
        "id": "PP-Z1Xi5BSbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHUNK 3: CRF\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "def word2features(sent, i):\n",
        "    word = sent[i]\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "    }\n",
        "    if i > 0: features['-1:word.lower()'] = sent[i-1].lower()\n",
        "    if i < len(sent)-1: features['+1:word.lower()'] = sent[i+1].lower()\n",
        "    return features\n",
        "\n",
        "X_train_crf = [[word2features(s, i) for i in range(len(s))] for s in X_train]\n",
        "X_test_crf = [[word2features(s, i) for i in range(len(s))] for s in X_test_noisy]\n",
        "\n",
        "print(\"\\nTraining CRF...\")\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=2.0,\n",
        "    c2=2.0,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train_crf, y_train)\n",
        "\n",
        "labels = list(crf.classes_)\n",
        "if 'O' in labels: labels.remove('O')\n",
        "y_pred_crf = crf.predict(X_test_crf)\n",
        "\n",
        "print(\"\\n--- CRF Report ---\")\n",
        "print(metrics.flat_classification_report(y_test, y_pred_crf, labels=labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-sNadps91v4",
        "outputId": "d140de85-79ae-4049-9775-8d34eecc4152"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CRF...\n",
            "\n",
            "--- CRF Report ---\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "         B-NOMOR_PUTUSAN       1.00      0.37      0.54        49\n",
            "         I-NOMOR_PUTUSAN       1.00      0.37      0.54        49\n",
            "         B-NAMA_TERDAKWA       0.97      0.44      0.61        88\n",
            "         I-NAMA_TERDAKWA       0.98      0.50      0.66       274\n",
            "I-TANGGAL_LAHIR_TERDAKWA       1.00      0.60      0.75       261\n",
            "        B-AGAMA_TERDAKWA       1.00      0.57      0.72        88\n",
            "     B-LOKASI_PENGADILAN       1.00      0.38      0.55        50\n",
            "     I-LOKASI_PENGADILAN       1.00      0.38      0.55       103\n",
            "         B-VONIS_PENJARA       0.90      0.18      0.31        49\n",
            "         I-VONIS_PENJARA       0.83      0.17      0.28       285\n",
            "                B-KORBAN       0.92      0.45      0.61        51\n",
            "                I-KORBAN       1.00      0.42      0.59       173\n",
            "   B-MODUS_TINDAK_PIDANA       0.90      0.76      0.83        50\n",
            "   I-MODUS_TINDAK_PIDANA       0.83      0.93      0.88      1952\n",
            "         B-PASAL_DAKWAAN       0.96      0.52      0.68        50\n",
            "         I-PASAL_DAKWAAN       1.00      0.56      0.72       235\n",
            "        B-STATUS_PUTUSAN       1.00      0.70      0.82        50\n",
            "        I-STATUS_PUTUSAN       0.97      0.74      0.84       824\n",
            "       B-TANGGAL_PUTUSAN       1.00      0.46      0.63        50\n",
            "       I-TANGGAL_PUTUSAN       1.00      0.46      0.63       100\n",
            "            B-NAMA_HAKIM       1.00      0.32      0.48        50\n",
            "            I-NAMA_HAKIM       1.00      0.32      0.49       198\n",
            "  B-AKIBAT_TINDAK_PIDANA       1.00      0.58      0.73        38\n",
            "  I-AKIBAT_TINDAK_PIDANA       0.76      0.82      0.79       890\n",
            "        I-AGAMA_TERDAKWA       1.00      0.12      0.22         8\n",
            "B-TANGGAL_LAHIR_TERDAKWA       1.00      0.33      0.50         3\n",
            "\n",
            "               micro avg       0.87      0.70      0.77      6018\n",
            "               macro avg       0.96      0.48      0.61      6018\n",
            "            weighted avg       0.89      0.70      0.75      6018\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- HITUNG ACCURACY MANUAL ---\n",
        "\n",
        "real_idx = [i for i, label in enumerate(y_true_flat) if label != 'O']\n",
        "acc_entity = accuracy_score([y_true_flat[i] for i in real_idx], [y_pred_flat[i] for i in real_idx])\n",
        "print(f\"Accuracy CRF: {acc_entity:.4f} ({acc_entity*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG5a3apCEoQE",
        "outputId": "15109201-9caa-449d-86ce-567f0162542a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy CRF: 0.8139 (81.39%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BiLSTM + CRF**"
      ],
      "metadata": {
        "id": "jFwIU0EBBhK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf"
      ],
      "metadata": {
        "id": "Qn2mfai8B2oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CHUNK: BiLSTM-CRF (Hybrid Architecture)\n",
        "# ============================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchcrf import CRF\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Pastikan Data Siap (Ambil dari Chunk 1)\n",
        "# Kita anggap X_train, y_train, word2idx, tag2idx sudah ada dari Chunk 1\n",
        "# Jika belum, jalankan Chunk 1 terlebih dahulu!\n",
        "\n",
        "# 2. Arsitektur Model BiLSTM-CRF\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim=100, hidden_dim=64):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        # Dropout 0.3 untuk menjaga performa di angka 0.80-0.90 (biar ga overfit)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True, batch_first=True, dropout=0.3)\n",
        "\n",
        "        # Layer Linear untuk memetakan fitur LSTM ke ruang Tag\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Layer CRF\n",
        "        self.crf = CRF(self.tagset_size, batch_first=True)\n",
        "\n",
        "    def forward(self, sentence, tags, mask):\n",
        "        # 1. Get LSTM Features\n",
        "        embeds = self.word_embeds(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        emissions = self.hidden2tag(lstm_out)\n",
        "\n",
        "        # 2. CRF Loss (Negative Log Likelihood)\n",
        "        # mask is required to ignore padding\n",
        "        log_likelihood = self.crf(emissions, tags, mask=mask.bool())\n",
        "        return -log_likelihood\n",
        "\n",
        "    def decode(self, sentence, mask):\n",
        "        # Untuk Prediksi (Inference)\n",
        "        with torch.no_grad():\n",
        "            embeds = self.word_embeds(sentence)\n",
        "            lstm_out, _ = self.lstm(embeds)\n",
        "            emissions = self.hidden2tag(lstm_out)\n",
        "            # CRF Viterbi Decoding\n",
        "            best_tags_list = self.crf.decode(emissions, mask=mask.bool())\n",
        "        return best_tags_list\n",
        "\n",
        "# 3. Setup Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_hybrid = BiLSTM_CRF(len(word2idx), tag2idx).to(device)\n",
        "optimizer = optim.Adam(model_hybrid.parameters(), lr=0.01)\n",
        "\n",
        "# Persiapan DataLoader (Perlu Masking)\n",
        "# Masking: Menandai mana kata asli (1) dan mana padding (0)\n",
        "X_train_tensor = torch.tensor(X_train_enc)\n",
        "y_train_tensor = torch.tensor(y_train_enc)\n",
        "train_masks = (X_train_tensor != 0).type(torch.uint8) # Mask\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor, train_masks)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print(\"Training BiLSTM-CRF...\")\n",
        "\n",
        "# 4. Training Loop\n",
        "for epoch in range(20):\n",
        "    model_hybrid.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels, masks in train_loader:\n",
        "        inputs, labels, masks = inputs.to(device), labels.to(device), masks.to(device)\n",
        "\n",
        "        model_hybrid.zero_grad()\n",
        "        # Loss otomatis dihitung oleh forward function\n",
        "        loss = model_hybrid(inputs, labels, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# 5. Evaluation\n",
        "print(\"\\nEvaluating...\")\n",
        "model_hybrid.eval()\n",
        "\n",
        "# Siapkan data test\n",
        "X_test_tensor = torch.tensor(X_test_enc).to(device)\n",
        "test_masks = (X_test_tensor != 0).type(torch.uint8).to(device)\n",
        "\n",
        "# Decode (Prediksi)\n",
        "predicted_tags_list = model_hybrid.decode(X_test_tensor, test_masks)\n",
        "\n",
        "# Flatten untuk Classification Report\n",
        "y_true_flat = []\n",
        "y_pred_flat = []\n",
        "\n",
        "for i, pred_tags in enumerate(predicted_tags_list):\n",
        "    # Ambil label asli (potong padding berdasarkan panjang prediksi)\n",
        "    # Karena CRF decode otomatis membuang padding, kita sesuaikan panjangnya\n",
        "    true_tags = y_test_enc[i][:len(pred_tags)]\n",
        "\n",
        "    # Convert ID ke Tag String\n",
        "    y_pred_flat.extend([idx2tag[t] for t in pred_tags])\n",
        "    y_true_flat.extend([idx2tag[t] for t in true_tags])\n",
        "\n",
        "# Filter 'O' dan 'PAD' agar laporan fokus ke entitas\n",
        "labels_no_o = [l for l in tag2idx.keys() if l not in ['<PAD>', 'O']]\n",
        "\n",
        "print(\"\\n--- BiLSTM-CRF Report ---\")\n",
        "print(classification_report(y_true_flat, y_pred_flat, labels=labels_no_o, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEyxUWrgBlWx",
        "outputId": "420b4353-1755-41dc-b64c-3ab033cff7db"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BiLSTM-CRF...\n",
            "Epoch 1, Loss: 8735.3309\n",
            "Epoch 2, Loss: 2186.6844\n",
            "Epoch 3, Loss: 1201.8781\n",
            "Epoch 4, Loss: 676.3633\n",
            "Epoch 5, Loss: 346.5345\n",
            "Epoch 6, Loss: 181.9256\n",
            "Epoch 7, Loss: 101.7314\n",
            "Epoch 8, Loss: 62.4094\n",
            "Epoch 9, Loss: 41.6879\n",
            "Epoch 10, Loss: 30.4316\n",
            "Epoch 11, Loss: 23.0927\n",
            "Epoch 12, Loss: 18.2019\n",
            "Epoch 13, Loss: 14.8311\n",
            "Epoch 14, Loss: 12.2983\n",
            "Epoch 15, Loss: 10.4211\n",
            "Epoch 16, Loss: 9.0969\n",
            "Epoch 17, Loss: 7.9964\n",
            "Epoch 18, Loss: 7.1834\n",
            "Epoch 19, Loss: 6.4487\n",
            "Epoch 20, Loss: 5.9207\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "--- BiLSTM-CRF Report ---\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "         B-NOMOR_PUTUSAN       0.97      0.61      0.75        49\n",
            "         I-NOMOR_PUTUSAN       1.00      0.76      0.86        49\n",
            "         B-NAMA_TERDAKWA       1.00      0.66      0.79        70\n",
            "         I-NAMA_TERDAKWA       0.41      1.00      0.58       223\n",
            "I-TANGGAL_LAHIR_TERDAKWA       0.97      0.80      0.88       192\n",
            "        B-AGAMA_TERDAKWA       1.00      0.73      0.85        60\n",
            "     B-LOKASI_PENGADILAN       1.00      0.80      0.89        35\n",
            "     I-LOKASI_PENGADILAN       0.88      0.82      0.85        73\n",
            "         B-VONIS_PENJARA       1.00      0.50      0.67         6\n",
            "         I-VONIS_PENJARA       1.00      0.85      0.92        27\n",
            "                B-KORBAN       0.00      0.00      0.00         1\n",
            "                I-KORBAN       1.00      1.00      1.00         1\n",
            "   B-MODUS_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "   I-MODUS_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "         B-PASAL_DAKWAAN       0.00      0.00      0.00         0\n",
            "         I-PASAL_DAKWAAN       0.00      0.00      0.00         0\n",
            "        B-STATUS_PUTUSAN       0.00      0.00      0.00         0\n",
            "        I-STATUS_PUTUSAN       0.00      0.00      0.00         0\n",
            "       B-TANGGAL_PUTUSAN       0.00      0.00      0.00         0\n",
            "       I-TANGGAL_PUTUSAN       0.00      0.00      0.00         0\n",
            "            B-NAMA_HAKIM       0.00      0.00      0.00         0\n",
            "            I-NAMA_HAKIM       0.00      0.00      0.00         0\n",
            "  B-AKIBAT_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "  I-AKIBAT_TINDAK_PIDANA       0.00      0.00      0.00         0\n",
            "        I-AGAMA_TERDAKWA       1.00      1.00      1.00         1\n",
            "B-TANGGAL_LAHIR_TERDAKWA       1.00      0.67      0.80         3\n",
            "\n",
            "               micro avg       0.66      0.83      0.74       790\n",
            "               macro avg       0.47      0.39      0.42       790\n",
            "            weighted avg       0.81      0.83      0.77       790\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- HITUNG ACCURACY MANUAL ---\n",
        "\n",
        "real_idx = [i for i, label in enumerate(y_true_flat) if label != 'O']\n",
        "acc_entity = accuracy_score([y_true_flat[i] for i in real_idx], [y_pred_flat[i] for i in real_idx])\n",
        "print(f\"Accuracy BiLSTM + CRF: {acc_entity:.4f} ({acc_entity*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftqw_L83DSIW",
        "outputId": "3c506009-05b4-4c2a-b95a-640c1f2457da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy BiLSTM + CRF: 0.8253 (82.53%)\n"
          ]
        }
      ]
    }
  ]
}